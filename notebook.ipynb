{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wADwK78DCz"
      },
      "source": [
        "# Proyek Klasifikasi Gambar: [Garbage Dataset](https://www.kaggle.com/datasets/sumn2u/garbage-classification-v2)\n",
        "- **Nama:** Patuh Rujhan Al Istizhar\n",
        "- **Email:** patuh41@gmail.com\n",
        "- **ID Dicoding:** patuh_istizhar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-z4QGlO8DC1"
      },
      "source": [
        "## Import Semua Packages/Library yang Digunakan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVYwaObI8DC1",
        "outputId": "29c361ca-f72c-454b-b055-56c09e893e9a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import splitfolders\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "from PIL import Image\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization,\n",
        "    Conv2D,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    MaxPooling2D,\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK4DvqfbYrN8"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1mJE9UgnE14"
      },
      "outputs": [],
      "source": [
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Constants\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHekw29KX4XQ"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "dataset_path = kagglehub.dataset_download(\"sumn2u/garbage-classification-v2\")\n",
        "data_dir = os.path.join(dataset_path, \"garbage-dataset\")\n",
        "\n",
        "\n",
        "# Load dataset into a DataFrame\n",
        "image_paths = []\n",
        "class_labels = []\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for filename in os.listdir(class_dir):\n",
        "            image_paths.append(os.path.join(class_dir, filename))\n",
        "            class_labels.append(class_name)\n",
        "df = pd.DataFrame({\"image_path\": image_paths, \"label\": class_labels})\n",
        "print(f\"Loaded {len(df)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot class distribution\n",
        "class_counts = df[\"label\"].value_counts()\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.barplot(\n",
        "    x=class_counts.index,\n",
        "    y=class_counts.values,\n",
        "    hue=class_counts.index,\n",
        "    palette=\"viridis\",\n",
        ")\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFgLyQPHX98s"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ICO2-E0YxzD"
      },
      "source": [
        "#### Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "LmSYvmyp8Xc7",
        "outputId": "b1a4c9c6-4588-46dc-90af-9878e0f5b2bf"
      },
      "outputs": [],
      "source": [
        "splitfolders.ratio(data_dir, output=\"data_split\", seed=42, ratio=(0.8, 0.1, 0.1))\n",
        "train_dir = \"data_split/train\"\n",
        "val_dir = \"data_split/val\"\n",
        "test_dir = \"data_split/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ImageDataGenerator for data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Create data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False,\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc-Ph-oIYAUU"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "UTwK0t8XYAUU",
        "outputId": "4433d194-ece2-4d0c-b996-b3bf8541fb46"
      },
      "outputs": [],
      "source": [
        "# Build CNN model\n",
        "num_classes = len(train_generator.class_indices)\n",
        "model = Sequential(\n",
        "    [\n",
        "        # Convolutional layers\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        BatchNormalization(),\n",
        "        # Classifier\n",
        "        Flatten(),\n",
        "        Dense(256, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# Set Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        patience=8, restore_best_weights=True, monitor=\"val_accuracy\", verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        \"best_model.keras\", save_best_only=True, monitor=\"val_accuracy\", verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(patience=4, factor=0.5, min_lr=0.000001, verbose=1),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XctzCfzbYCBK"
      },
      "source": [
        "## Evaluasi dan Visualisasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKk-ScZWYCBK"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "train_loss, train_acc = model.evaluate(train_generator)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_acc:.4f} ({train_acc * 100:.2f}%)\")\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc * 100:.2f}%)\")\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.axhline(y=0.95, color=\"r\", linestyle=\"--\", label=\"Target (95%)\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_fIsUogYFSk"
      },
      "source": [
        "## Konversi Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths\n",
        "tfjs_model_path = \"tfjs_model\"\n",
        "tflite_model_path = \"tflite/model.tflite\"\n",
        "tflite_label_path = \"tflite/label.txt\"\n",
        "saved_model_path = \"saved_model\"\n",
        "\n",
        "# Clean and create directories\n",
        "for path in [tfjs_model_path, \"tflite\", saved_model_path]:\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n",
        "\n",
        "# Save in SavedModel format\n",
        "tf.saved_model.save(model, saved_model_path)\n",
        "print(f\"SavedModel saved at: {saved_model_path}\")\n",
        "\n",
        "# Save in TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open(tflite_model_path, \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "print(f\"TFLite model saved at: {tflite_model_path}\")\n",
        "\n",
        "# Save labels for TFLite\n",
        "labels = list(train_generator.class_indices.keys())\n",
        "with open(tflite_label_path, \"w\") as f:\n",
        "    for label in labels:\n",
        "        f.write(f\"{label}\\n\")\n",
        "print(f\"Labels saved at: {tflite_label_path}\")\n",
        "\n",
        "# Save in TF.js format\n",
        "tfjs.converters.save_keras_model(model, tfjs_model_path)\n",
        "print(f\"TF.js model saved at: {tfjs_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DbfEwvvm5U4"
      },
      "source": [
        "## Inference (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue5esMSSm8GQ"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Load and preprocess a sample image\n",
        "sample_image_path = os.path.join(\n",
        "    test_dir,\n",
        "    os.listdir(test_dir)[0],\n",
        "    os.listdir(os.path.join(test_dir, os.listdir(test_dir)[0]))[0],\n",
        ")\n",
        "image = Image.open(sample_image_path).convert(\"RGB\")\n",
        "image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "image_array = np.array(image) / 255.0\n",
        "input_image = np.expand_dims(image_array, axis=0).astype(np.float32)\n",
        "\n",
        "# Perform inference\n",
        "interpreter.set_tensor(input_details[0][\"index\"], input_image)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "predicted_class = np.argmax(output_data)\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "# Show image and prediction\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(f\"Predicted Class: {predicted_label}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
